{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a02894",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Computer vision pipeline </span>\n",
    "1.Input data  \n",
    "2.Preprocessing  \n",
    "-> Reduce computation complexity  \n",
    "-> Data augmentation  \n",
    "3.Feature extraction: Find distinctive information about the image  \n",
    "4.ML model: Learn extracted features to predict output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48d8ee",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Why multilayer perceptrons were introduced </span>\n",
    "A single perceptron can't solve nonlinear problem which is much more complex in real world.\n",
    "<img src = \"./img/multilayer_perceptrons.png\" width = \"250\" height = \"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02153d38",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Weight? </span>  \n",
    "Weight parameters reflect the usefulness (or importance) of these features on the output prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab8ecf",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Hyperparameters for a neural network </span>\n",
    "1.Number of hidden layers\n",
    "- The more neurons a network have, the better the network will learn the training data. -> Cause overfitting\n",
    "2.Activation function\n",
    "- Purpose: to introduce nonlinearity into a network. To be specific, we can get nonlinear output from an activation function. No matter how many hidden layers are stacked, linear system can make only linear systems, not nonlinear systems.\n",
    "3.Error function\n",
    "- Measures how far the network’s prediction is from the true label\n",
    "- Regression problem: Mean square error / Classification problem: cross-entropy\n",
    "4.Optimizer\n",
    "- A function that implements a specific way to reach the objective of minimizing the cost function. About how much to change the weights.\n",
    "5.Batch size\n",
    "- ?\n",
    "6.Number of epochs\n",
    "- ?\n",
    "7.Learning rate\n",
    "- The size of each step the network takes when it descends the error mountain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d74ce",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Forwardpropagation vs Backpropagation </span>\n",
    "- The forward pass calculates the output prediction (left). The backward pass passes the derivative of the error backward to update its weights (right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa60ccd",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Supervised vs Unsupervised vs Reinforcement Learning </span>\n",
    "<img src = \"./img/types_of_ML.png\" width = \"500\" height = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e32613",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Explain with an example why the inputs in computer vision problems can get huge. Provide a solution to overcome this challenge. </span>\n",
    "Let's say that there is a 400x400 RGB image as an input in a fully connected network. The number of the image is 400x400x3 = 480,000. we deal with a lot of images when training the network, not only one. Therefore, it could increase enormously depending on a dataset. Preprosessing such as resize and converting image to black and white is needed to overcome this challenge.\n",
    "Additionally, if the number of weights is too much due to many hidden layers, we can use convolution operation to address this challenge. Convolution operation works as following.\n",
    "<img src = \"./img/convolution.png\" width = \"500\" height = \"500\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5a4a0",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Explain with overfitting and underfitting. Provide a solution to overcome this challenge. </span>\n",
    "- Underfitting means a ML model fails to fit/learn the traning data. This happens when the model is too simple to fit the data.\n",
    "- Overfitting means a ML model fits/learns the data too much. To be specific, the model just memorize the training data and don't learn the features. This happens when the training data size is too small and does not contain enough data samples to accurately represent all possible input data values or the nubmer of epoches for traning is too much.\n",
    "- To avoid underfitting, we should maintain adequate model complexity. For example, first we can decrease regularization. By decreasing the amount of regularization, more complexity and variation is introduced into the model, allowing for successful training of the model. There are a number of different regularization methods, such as L1 regularization, Lasso regularization, dropout, etc. Second, Increase the duration of training. Last, Feature selection. We might add more hidden neurons or in a random forest, we may add more trees. This process will inject more complexity into the model, yielding better training results.\n",
    "- To avoid overfitting, there are a number of techniques. First, Early stopping. This method find the sweet spot between underfitting and overfitting by pausing traning right before overftting. Second, Train with more data. This can increase the accuracy of the model by letting the model learn clearly the features with more data. Third, Data augmentation. Forth, Regularization. If overfitting occurs when a model is too complex, it makes sense for us to reduce the number of features. Regularization applies a “penalty” to the input parameters with the larger coefficients, which subsequently limits the amount of variance in the model. There are a number of regularization methods such as L1 regularization, Lasso regularization, and dropout, they all seek to identify and reduce the noise within the data. Last, Ensembel methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b25fb9",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> What are the features likely to be detected by the initial layers of a neural network used for Computer Vision? How is this different from what is detected by the later layers of the neural network? </span>\n",
    "The earlier layers of the neural network detect simple features of an image, such as edges or corners. As we go deeper into the neural network, the features become increasingly complex, detecting shapes and patterns. The later layers of the neural network are capable of detecting complex patterns such as complete objects. Refer to the following figure.\n",
    "<img src = \"./img/feature_extraction.png\" width = \"250\" height = \"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237f777",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> How do you address the issue of the edge pixels being used less than the central pixels during convolutional operation? </span>\n",
    "- We can use padding to deal with the problem. Padding is adding one or more additional rows or columns of pixels along the boundry of the image. The edge pixels being used less means the network loses the information of the edge in a feature extraction process. We can keep the information by adding additional pixels along the boundry of the image, which is called padding.\n",
    "- Padding is most commonly used to allow us to preserve the spatial size of the input volume so the input and output width and height are the same. This way, we can use convolutional layers without necessarily shrinking the height and width of the volumes. Why do we prevent the image from schrinking? Otherwise, we will lose all the important details of the image for the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c784e7",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> Why do we need pooling layers?</span>\n",
    "Subsampling or pooling helps reduce the size of the network by reducing the number of parameters passed to the next layer. This is because the increase of prameters(weights) increases the time of the mathmatical operations in the learning process, or computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10babb4",
   "metadata": {},
   "source": [
    "#### <span style = \"color:red\"> After the convolutional layers, the image keeps its width and height dimensions (usually), but it gets deeper and deeper after each layer. Why? Explain it using the following figure.</span>\n",
    "<img src = \"./img/convolution_deep.png\" width = \"500\" height = \"500\">\n",
    "일반적으로 Conv 필터는 이미지의 특정 패턴을 잡아내는데 사용됩니다. 초반에 위치한 Layer들은 주로 사물을 구성하는 edge나 corner와 같은 좀 더 상세한 패턴을 잡아냅니다.\n",
    "하지만 이 패턴만으로 이미지를 판별하기는 부족합니다. 오히려 이러한 상세 패턴은 다양한 유형으로 존재하면서 Noise나 오버피팅(즉 학습 데이터와 굉장히 동일한 데이터 세트가 아니라 좀 더 일반적인 데이터 세트에서는 성능이 저하되는 현상)으로 적절한 이미지 분류로 동작하기는 어렵습니다. \n",
    "그래서 이들 상세화된 패턴들이 결합된 보다 일반적인 패턴(예를 들어 동그라미라던가)으로 만들어 내는데 이를 위해서 Conv 필터의 채널수를 더욱 증가 시키게 됩니다. 이게 초기 CNN을 연구하면서 필터수를 증가시키면 상세 정보는 손실되지만 보다 일반적이고 추상화된 패턴을 잡아낼 수 있다는 것이 밝혀지면서 이렇게 필터수를 증가 시키게 되었습니다. \n",
    "사실 이런 일반적인 패턴들을 뽑아내는 것이 개별적으로 상세화된 패턴을 뽑아내는 것보다 훨씬 복잡한 연산이 필요합니다. 개별적으로 상세화된 패턴을 보다 복잡하게 결합하여 보다 일반화된 패턴을 뽑아내야 하기 때문입니다. 그래서 더 많은 채널수를 가지게 됩니다.\n",
    "*Number of filters? 132p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720596f",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\"> For a 10x10 image used with a 5x5 filter, what should the padding be in order to obtain a resultant image of the same size as the original image?</span>\n",
    "When padding = 2, we can obtain a resultant image of the same size as the original image as following picture.\n",
    "<img src = \"./img/padding.png\" width = \"300\" hegiht = \"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef74aaf",
   "metadata": {},
   "source": [
    "#### <span style = \"color:red\"> For an RGB image of dimensions 10x10x3 convolved with a 3x3 filter, what will be the size of the resultant image?</span>\n",
    "The convolution operation is not possible for a 10x10x3 image with a 3x3 filter as the third dimension (or the number of channels) must be the same in order to achieve convolution. Alternatively, if a 10x10x3 image is convolved with a 3x3x3 filter, the dimensions of the resultant image will be 4x4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e7d1e",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\">  In order to extract multiple features from an image, it is common practice to use a number of filters and then stack them up to form the resultant. So for a 10x10x3 image convoluted using ten filters of dimensions 5x5x3, how many parameters must be learned to form the filters alone? </span>\n",
    "Each 5x5x3 filter has 5*5*3=75 features. Therefore for ten such filters, the total number of features will be 75*10=750 features. (NOTE: The bias has not been accounted for in this calculation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41437d",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\">Suggest a way to train a convolutional neural network when you have a quite small dataset.</span>\n",
    "- Transfer learning: It is the transfer of the knowledge (feature\n",
    "maps) that the network has acquired from one task, where we have a large amount of data, to a new task where data is not abundantly available.\n",
    "- Data augmentation: Techniques like mirroring, random cropping, and shearing can help augment the existing dataset and create more training data from the existing data, thereby sovling the issue of limited training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113cb90",
   "metadata": {},
   "source": [
    "#### <span style = \"color:blue\">Mention a method that can be used to evaluate an object localization model. How does it work?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://www.projectpro.io/article/computer-vision-engineer-interview-questions/450"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
